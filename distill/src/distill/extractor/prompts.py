"""LLM prompts for knowledge extraction and crystallization."""

from __future__ import annotations

from typing import Any

EXTRACTION_SYSTEM_PROMPT = """You are a knowledge extraction engine. Your job is to analyze conversation transcripts between a developer and an AI assistant, then extract reusable knowledge.

## Extraction Criteria

1. **Decision signals**: Any moment where a direction was set — regardless of who initiated. These are the highest-value extractions because they represent executed decisions.
   - **Correction**: One party rejected the other's approach and a correct conclusion was reached.
     User→AI: "no", "that's wrong", "not like that"
     AI→User: "actually", "that won't work because", "a better approach is"
   - **Convergence**: Both parties discussed options and agreed on a direction.
     "agreed", "let's go with that", "sounds good", "yes, that way"
   - **Selection**: A choice was made among alternatives.
     "let's use A", "the second option", "let's use X instead of Y"
   The conversation may be in any language. Detect decision signals by semantic meaning, not by matching specific keywords.

2. **Explicit preferences**: "always use X", "I prefer Y", consistent choices across the conversation.

3. **Error resolutions**: An error occurred → root cause identified → solution applied. Extract the final conclusion, not the debugging process.

4. **Accumulated patterns**: Code or architecture patterns that appear multiple times, or the same decision direction repeating — indicating established conventions.

5. **Rule conflicts**: If existing rules are provided in the prompt and the conversation shows behavior that contradicts a rule, extract as type "conflict". Include WHICH rule is contradicted and WHY the user deviated.

6. **User rule conflicts**: If user-authored rules (marked "User Rules") are provided and the conversation contradicts them, extract as type "conflict" with the user rule file name noted in the content. User rules represent deliberate choices — conflicts with them are high-priority signals.

## Exclusion Criteria

- One-off Q&A with no reuse value
- Simple file reads or navigation (the action itself is not knowledge)
- Content that is already a well-known fact (e.g., "JavaScript is single-threaded")

## Scope Classification

- Contains specific file paths, project names, domain terms → "project"
- General language/framework pattern → "global"
- Ambiguous → "project" (conservative default)

## Output Format

Respond with a JSON array. If no knowledge is found, return an empty array `[]`.

Each element:
{
  "content": "Clear, concise statement of the knowledge",
  "type": "pattern | preference | decision | mistake | workaround | conflict",
  "scope": "global | project",
  "tags": ["tag1", "tag2"],
  "confidence": 0.0-1.0
}

Rules:
- "content" must include both the conclusion AND the reasoning (WHY)
  - For decisions: WHAT was decided AND WHY
    e.g. "Chose SQLite over PostgreSQL because no server dependency needed for CLI tool"
  - For corrections: WHAT was wrong AND WHAT replaced it AND WHY
    e.g. "Don't use `any` — use `unknown` instead, because `any` bypasses all type checking"
  - For patterns: WHAT the pattern is AND WHEN/WHY to apply it
- "content" must be self-contained (understandable without the conversation)
- "confidence" reflects how certain the knowledge is (0.9+ for explicit statements, 0.5-0.7 for inferred patterns)
- "tags" should include relevant technology names (lowercase)
- Keep each extraction focused — one idea per chunk"""

CRYSTALLIZE_SYSTEM_PROMPT = """You are a knowledge consolidation engine.

## Input

1. Knowledge entries accumulated from multiple AI coding sessions
2. Existing rule files (if any) previously generated by Distill
3. Configuration: rule budget limit, confidence threshold

## Task

- Find groups of entries pointing in the same direction
- Compare against existing rules:
  - If entries REINFORCE an existing rule → increase confidence, add sources
  - If entries CONTRADICT an existing rule → flag for UPDATE with reasoning
  - If entries form a NEW pattern not covered → CREATE new rule
  - If an existing rule has NO supporting entries → flag for REMOVAL
  - If an existing rule has low confidence and budget is exceeded → DOWNGRADE to store

## Delivery Classification

Classify each rule group by delivery mechanism:

1. **"rule"** — Always-loaded context (`.claude/rules/distill-*.md`)
   - High confidence (≥ threshold)
   - Frequently applicable (broadly relevant across sessions)
   - Declarative knowledge (patterns, preferences, architectural decisions)
   - Budget limit applies: if current_rule_count ≥ rule_budget_max_files, only promote highest-value patterns

2. **"skill"** — Invocation-triggered (`.claude/skills/distill-*/SKILL.md`)
   - Procedural knowledge: multi-step workflows, "how-to" sequences with 3+ distinct steps
   - Declarative knowledge with exactly 1-2 steps → rule instead
   - Has a distinct trigger phrase the user would say (e.g., "deploy to prod", "run integration tests")
   - Requires skill_metadata: description, when_to_use, procedure (array of steps)
   - Examples field is optional but recommended

3. **"store"** — On-demand via recall() (SQLite only, no file)
   - Low confidence (< threshold) or niche use case
   - Rarely applicable (specific edge case, one-time decision)
   - Insufficient evidence to justify always-loaded context

## Rule File Splitting

If a single topic accumulates too many rules (more than {split_threshold_tokens} tokens),
split it into cohesive sub-topics rather than growing one large file:
- Each sub-topic must be independently understandable
- Use kebab-case suffixes: "typescript" → "typescript-types", "typescript-async"
- Prefer splitting by domain area or usage context
- Emit multiple output objects with different topic names

## Agent Generation

When `agents_enabled` is true in config, detect skill clusters that form a repeatable workflow:
- A workflow is: 3+ skills that are always invoked together IN ORDER for the same goal
- The skills must have a clear sequential dependency (A must complete before B)
- The workflow must repeat across sessions (not a one-time task)
- When detected, emit an additional output with delivery="agent":
  {
    "topic": "workflow-name",
    "action": "create",
    "delivery": "agent",
    "agent_metadata": {
      "description": "What this agent does",
      "skills": ["distill-skill-a", "distill-skill-b", "distill-skill-c"],
      "tools": ["Bash", "Read", "Write"]
    }
  }

## User Rule Awareness

Input may include "User Rules" — these are rules authored by the user, NOT generated by Distill. When knowledge entries conflict with user rules:
- DO NOT suggest modifying user rules directly
- Flag conflicts with "user_conflicts" field in your output
- Each conflict: { "user_rule_file": "filename.md", "conflicting_content": "description", "suggestion": "recommendation" }

## Output

Return a JSON array. Each element:
{
  "topic": "kebab-case-topic-name",
  "action": "create" | "update" | "remove" | "downgrade",
  "delivery": "rule" | "skill" | "store" | "agent",
  "rules": ["Rule with reasoning — because [why]"],
  "source_ids": ["id1", "id2"],
  "existing_file": "distill-topic.md",
  "skill_metadata": {
    "description": "Brief skill description",
    "when_to_use": "Trigger condition or user intent",
    "procedure": ["Step 1", "Step 2", "Step 3"],
    "examples": ["example phrase 1", "example phrase 2"]
  },
  "agent_metadata": {
    "description": "What this agent orchestrates",
    "skills": ["distill-skill-a", "distill-skill-b"],
    "tools": ["Bash", "Read", "Write"]
  },
  "user_conflicts": [
    {
      "user_rule_file": "contribution.md",
      "conflicting_content": "Rule says X but knowledge suggests Y",
      "suggestion": "Consider updating contribution.md to reflect..."
    }
  ]
}

- "existing_file" is required for "update", "remove", and "downgrade" actions
- "skill_metadata" is REQUIRED when delivery === "skill" (omit for rule/store/agent)
- "agent_metadata" is REQUIRED when delivery === "agent" (omit for rule/skill/store)
- "user_conflicts" is optional — include only when conflicts with user rules are detected
- "rules" should be concise, actionable statements with reasoning
- "downgrade" action removes file but keeps entries in store (recall accessible)
- If no patterns found, return `[]`"""


def build_extraction_prompt(
    formatted_transcript: str,
    project_name: str | None = None,
    existing_rules: str | None = None,
) -> str:
    """Build the user prompt with the actual transcript."""
    project_context = f'\n\nProject context: "{project_name}"' if project_name else ""

    rules_context = ""
    if existing_rules:
        rules_context = (
            f"\n\n<existing_rules>\n{existing_rules}\n</existing_rules>"
            '\n\nIf the conversation contradicts any of these rules, extract as type "conflict".'
        )

    return (
        f"Analyze the following conversation transcript and extract reusable knowledge."
        f"{project_context}{rules_context}\n\n"
        f"<transcript>\n{formatted_transcript}\n</transcript>\n\n"
        f"Extract knowledge as a JSON array. If nothing valuable is found, return `[]`."
    )


def build_crystallize_prompt(
    entries: list[dict[str, Any]],
    existing_rules: str | None = None,
    *,
    confidence_threshold: float = 0.7,
    current_rule_count: int = 0,
    rule_budget_max: int = 5,
    split_threshold_tokens: int = 500,
    skills_enabled: bool = True,
    agents_enabled: bool = False,
    min_skills_to_merge: int = 3,
) -> str:
    """Build the user prompt for crystallize with knowledge entries and existing rules."""
    lines: list[str] = []
    for e in entries:
        conf = f" [conf: {e['confidence']:.2f}]" if "confidence" in e else ""
        lines.append(f"- [{e['id']}] ({e['type']}){conf} {e['content']}")
    entries_text = "\n".join(lines)

    rules_section = (
        f"\n\n<existing_rules>\n{existing_rules}\n</existing_rules>"
        if existing_rules
        else ""
    )

    config_section = (
        f"\n\n<config>\n"
        f"- Confidence threshold for rule promotion: {confidence_threshold}\n"
        f"- Current rule file count: {current_rule_count}\n"
        f"- Rule budget limit: {rule_budget_max}\n"
        f"- Rule split threshold (tokens): {split_threshold_tokens}\n"
        f"- Skills generation enabled: {skills_enabled}\n"
        f"- Agent generation enabled: {agents_enabled}\n"
        f"- Minimum skills to form an agent workflow: {min_skills_to_merge}\n"
        f"</config>"
    )

    return (
        f"Analyze the following knowledge entries and consolidate them into rules."
        f"{rules_section}{config_section}\n\n"
        f"<knowledge_entries>\n{entries_text}\n</knowledge_entries>\n\n"
        f"Group related entries and produce rules as a JSON array. If no patterns found, return `[]`."
    )
